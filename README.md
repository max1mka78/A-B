# Всем привет! :)
В данном проекте были  решены задачи подготовки к АБ тестированию, и сама реализация АБ тестирования.

### Исходные данные:

Мы присоединились к стартапу, который разрабатывает приложение с новостной лентой и возможностью отправки сообщений (доступно на **iOS** и **Android** ).
Дата инженеры посторались до нас, и нам доступны две обогащенные таблицы: одна — по взаимодействию пользователей с новостной лентой, вторая — по работе с мессенджером.
Данные хранятся в **ClickHouse** за период с 4 апреля по 5 июля 2025 года.

<hr>

## Основные задачи проекта

В рамках проекта были поставлены три ключевые задачи:

### Задача 1. Реализация системы сплитования

Настроить хэширование пользователей и корректное разбиение их на экспериментальные группы. Проверить, чтобы система сплитования соответствовала следующим критериям:
- **Случайность** — группы должны быть сформированы случайным образом.
- **Стабильность** — пользователь не должен менять группу в ходе теста.
- **Детерминированность** — разбиение должно быть воспроизводимым.

Цель: обеспечить чистоту A/B-теста и возможность обобщить результаты на всю аудиторию.

---

### Задача 2. Проведение A/B-тестирования

Провести полноценное A/B-тестирование двух новых алгоритмов рекомендаций:
- Алгоритм 1: посты, похожие на те, которые пользователь лайкал.
- Алгоритм 2: посты, популярные среди похожих пользователей.

Собрать данные по ключевым метрикам (в частности, CTR) и подготовить выборки для анализа.

---

### Задача 3. Анализ A/B-теста с использованием сглаженного CTR

Проанализировать результаты теста, используя **сглаженную метрику CTR**, чтобы минимизировать влияние случайных выбросов и получить более устойчивые и точные выводы. Определить, какой из алгоритмов показал лучшие результаты и заслуживает внедрения.

<hr>

### Описание данных:
  
## Таблица feed_actions (База данных новостной ленты)

* **user_id** - Уникальный номер пользователя

* **post_id** - Уникальный номер поста

* **acion** - Дейстиве пользователя
  * **like** - Поставить лайк на пост
  * **view** - Просмотреть пост
* **time** – дата совершения события

* **gender** - Гендер пользователя
  * **0** - Мужчина
  * **1** - Женщина
* **age** - Возраст пользователя

* **country** - Страна пользователя

* **city** - Город пользователя

* **os** - Операционная система пользователя
  * **iOS** - iOS
  * **Android** - Android
* **source** - Тип трафика

  * **ads** - Рекламный пользователь
  * **organic** - Органический пользователь

* **exp_group** - Номер экспериментальной группы пользователя в A/B-тесте

<hr>

## Таблица message_actions (База данных мессенджера)

* **user_id** - Уникальный номер отправителя

* **receiver_id** - Уникальный номер получателя

* **time** – дата совершения события

* **gender** - Гендер пользователя
  * **0** - Мужчина
  * **1** - Женщина
  
* **age** - Возраст пользователя

* **country** - Страна пользователя

* **city** - Город пользователя

* **os** - Операционная система пользователя
  * **iOS** - iOS
  * **Android** - Android
  
* **source** - Тип трафика
  * **ads** - Рекламный пользователь
  * **organic** - Органический пользователь

* **exp_group** - Номер экспериментальной группы пользователя в A/B-тесте

<hr>

# Что такое A/B-тестирование?

A/B-тестирование — это метод сравнения двух или более версий продукта с целью выявить, какая из них лучше влияет на ключевые метрики. Это один из самых надёжных способов принятия решений на основе данных.

## Зачем нужно A/B-тестирование?

На сайтах, приложениях и рекламных кампаниях часто возникают вопросы:
- Какой заголовок привлечёт больше кликов?
- Какой цвет кнопки «Купить» эффективнее: красный или синий?
- Увеличит ли новая функция время пребывания пользователя?

Чтобы ответить на эти вопросы объективно (а не "на глаз"), мы проводим A/B-тесты.

## Как устроен A/B-тест?

В тесте обычно участвуют две группы:

| Группа | Описание |
|--------|----------|
| **Control** | Пользователи видят текущую версию продукта |
| **Treatment** | Пользователи взаимодействуют с новой версией |

### Примеры метрик для анализа:
- **CTR (Click-through Rate)** — доля пользователей, кликнувших по элементу
- **Среднее время на сайте**
- **Доля лайков / просмотров**
- **Конверсия (например, оформление заказа)**
- **Retention (удержание)**

---

## На чём основано A/B-тестирование?

Тестирование использует **статистические методы**, такие как t-тест или Манна-Уитни, чтобы определить, является ли разница между группами реальной или случайной.

Например, если уровень значимости (`α`) равен 5%, это значит:
> Если разницы между группами на самом деле нет, тест всё равно может ошибочно показать её максимум в 5% случаев.

Это называется **ошибкой первого рода (FPR)**, и она помогает контролировать риск ложных выводов.

---

## Гипотеза: улучшат ли новые алгоритмы рекомендаций пользовательский опыт?

К нам обратилась команда машинного обучения с новыми алгоритмами рекомендаций в новостной ленте. Цель изменений — повысить удовлетворённость пользователей: увеличить LTV, улучшить конверсии, сделать использование продукта более приятным и удобным.

### Что хотим проверить?
Новые алгоритмы должны сделать посты **более интересными** для пользователей. Но как это измерить? Команда ML не дала конкретной целевой метрики — только общую идею: «пользователи будут видеть более релевантные посты».

Было разработано **два варианта алгоритма рекомендаций**:

1. **Алгоритм 1:** показываем посты, наиболее похожие на те, которые пользователь лайкал ранее.
2. **Алгоритм 2:** показываем посты, которые лайкали пользователи с похожими интересами.

Теперь задача аналитика — выбрать **ключевую метрику**, которая позволит понять, действительно ли изменения работают лучше, чем раньше.

---

### Возможные метрики

Мы рассмотрели несколько вариантов показателей, которые могут отразить повышение интереса к постам:

| Метрика | Описание |
|--------|----------|
| **Время, проведённое в ленте** | Показывает, насколько долго пользователь взаимодействует с контентом |
| **Количество просмотренных постов за сессию** | Отражает глубину прокрутки и интерес к новому контенту |
| **Количество лайков** | Прямое действие, говорящее о вовлечённости |
| **CTR (Click-through Rate)** | Отношение лайков к просмотрам |

---

### Почему мы выбрали CTR?

CTR — **наилучший индикатор качества рекомендаций**, потому что:

- Это **прямое действие пользователя**, которое говорит об интересе к контенту.
- Лайк — это чётко определённое событие, легко измеряемое и интерпретируемое.
- Это **стандартная метрика** в продуктовой аналитике, особенно в соцсетях и рекомендательных системах.
- CTR позволяет сравнивать эффективность алгоритмов между собой и с контрольной группой.

Формула CTR:
CTR = (Количество лайков / Количество просмотров) * 100%


---

### Вывод

Для оценки эффективности новых алгоритмов рекомендаций мы будем использовать **CTR как ключевую метрику**. Её увеличение будет означать, что посты стали **более релевантными и интересными** для пользователей.

## Система сплитования: как разбиваем пользователей на группы

Мы определили ключевую метрику — CTR, и теперь нужно провести A/B-тест, чтобы понять, какой алгоритм рекомендаций работает лучше. Но почему бы просто не запустить один из новых алгоритмов всем пользователям?

### Зачем нужен эксперимент?

Потому что любое изменение может повлиять на поведение пользователей непредсказуемым образом. Даже если алгоритм выглядит успешным в теории, он может привести к снижению вовлеченности, уменьшению количества лайков или даже оттоку аудитории. Мы не можем рисковать всей пользовательской базой без предварительной проверки.

Поэтому перед внедрением таких важных изменений мы тестируем их **на небольшой группе пользователей**, чтобы:
- Проверить гипотезу.
- Убедиться, что изменения не навредят другим метрикам.
- Получить статистически значимые результаты.

---

## Основные требования к сплитованию

Чтобы тест был корректным, система сплитования должна удовлетворять следующим условиям:

1. **Случайность разбиения**
2. **Стабильность группы пользователя**
3. **Детерминированность**

Рассмотрим каждое требование подробно.

---

### Случайность

Мы хотим, чтобы группы отличались **только** используемым алгоритмом рекомендаций. Всё остальное — возраст, география, устройство, частота использования — должно быть сбалансировано между группами.

Если этого не добиться, можно получить искажённые результаты:
- Например, в одной группе окажется больше пользователей из Москвы, в другой — из регионов.
- Или одни пользователи чаще заходят по будням, другие — по выходным.

Такие различия будут мешать интерпретации результатов.

>  **Цель:** Группы должны быть **статистически эквивалентны** друг другу и отражать общую картину по продукту.

---

### Стабильность группы пользователя

Во время проведения теста пользователь **не должен менять группу**. Это важно по двум причинам:

- Если пользователь видел оба алгоритма, его поведение может стать менее предсказуемым.
- Такие пользователи могут исказить результаты и сделать тест нерепрезентативным.

> Нельзя просто исключить таких пользователей из анализа — это нарушит случайность выборки.

---

### Детерминированность

Система сплитования должна работать **предсказуемо** и воспроизводимо. То есть, если мы снова запустим тот же самый тест, мы должны получить такое же разбиение на группы.

Это особенно важно, когда:
- Идут параллельные эксперименты.
- Нужно исключить пользователей, которые уже участвуют в другом тесте.

> Детерминированное разбиение позволяет избежать пересечения экспериментов и контролировать влияние нескольких изменений одновременно.

---

## Вывод

Правильная система сплитования — основа успешного A/B-теста.  
Она обеспечивает:
- Чистое сравнение между группами.
- Возможность обобщить результаты на всю пользовательскую базу.
- Контроль над параллельными экспериментами.

Соблюдение принципов **случайности**, **стабильности** и **детерминированности** помогает нам получать достоверные и полезные выводы.
